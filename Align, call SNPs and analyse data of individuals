# To analyse individuals could do:

# Fastqc and Multiqc the individuals
# Align to REF genome using BWA-MEM
# Make a VCF file using samtools
# Calculate Fst between whatever populations you choose using VCFtools.

# To call indels use FreeBayes or VarScan

# Note, had read the following paper before wrote the above! 
# Good paper which compared 7 short-read aligners and 10 variant calling algorithms. 
# Paper notes - Comparative analysis of whole-genome sequencing pipelines to minimize false negative findings
# Hwang et al 2019, https://www.nature.com/articles/s41598-019-39108-2

# SNPs: Samtools > VarScan > Platypus > FreeBayes
# Indels: FreeBayes / VarScan > Platypus  > Samtools
# GATKv3HC is also a good bet, but would need it installed.

################################# CODE ################################################################
################## Note, not yet tested! ##############################################################

# Quality check the sequencing reads:
# Note, want as input the fastq files.
# Fastqc (http://www.bioinformatics.babraham.ac.uk/projects/fastqc/):
for i in *gz; do fastqc $i ; done

# To MultiQC (Ewels et al., 2016) files:
multiqc *<common_end_of_directory>/*<suffix_of_file>

# Do you need to trim reads etc?

#####################################################################

# Align the data:
# Script belongs to Dr S. Doyle, WSI
# Uses samtools (Li et al., 2009) and BWA-MEM (Li, 2013; Li and Durbin, 2009)
# Put in the command line when run the script:

./run_bwa_splitter <sample_name> <reference.fa> <read1_file.fa> <read2_file.fa>

# BWA-MEM alignment of reads shell script for Pool-Seq:

#!/usr/bin/env bash
#####################################################################
# run_bwamem_splitter.sh
#
# sd21@sanger.ac.uk
# July 2018
#####################################################################
sample_name=$1
reference=$2
read1=$3
read2=$4

ID="U$(date +%s)"

if [ "$#" -eq 0 ] || [ "$1" == "-h" ] || [ "$1" == "--help" ]; then
        echo ""
    echo "Usage: ~sd21/bash_scripts/run_bwa_splitter <SAMPLE_PREFIX> <REFERENCE> <R1.fastq> <R2.fastq>"
    echo ""
    exit 0
fi

if [ -d "${sample_name}_bwasplitter_out" ]; then
        echo -e "\nThere is already a run started with this sample name. Rename and start again\n"
    exit 0
fi


mkdir ${sample_name}_bwasplitter_out
cd ${sample_name}_bwasplitter_out
mkdir logfiles

# prepare reference and split data
echo -e "# prepare reference and split the raw data
sample_name=$"{1}"
reference=$"{2}"
read1=$"{3}"
read2=$"{4}"
ln -sf $"{reference}" ref.fa
bwa index -b 100000000 ref.fa

if [[ $read1 =~ \.gz$ ]]
then ln -sf $"{read1}" R1.fq.gz; zcat R1.fq.gz | split -d -a 3 -l 4000000 - R1_tmp_
else ln -sf $"{read1}" R1.fq; split -d -a 3 -l 4000000 R1.fq R1_tmp_
fi

if [[ $read2 =~ \.gz$ ]]
then ln -sf $"{read2}" R2.fq.gz; zcat R2.fq.gz | split -d -a 3 -l 4000000 - R2_tmp_
else ln -sf $"{read2}" R2.fq; split -d -a 3 -l 4000000 R2.fq R2_tmp_
fi


#split -d -a 3 -l 4000000 R1.fq R1_tmp_
#split -d -a 3 -l 4000000 R2.fq R2_tmp_
touch step1_FINISHED" > step1_bwasplitter
chmod a+x step1_bwasplitter


# prepare split mapping and set off mapping
echo -e "# prepare the split mapping run files
sample_name=$"{1}"
n=0
for i in \` ls -1 R1_* \` ; do
let \"n+=1\"
echo -e \"bwa mem -t 4 -R '@RG\\\\\\\\\\\tRG:$"{sample_name}"\\\\\\\\\\\tID:$"{sample_name}"\\\\\\\\\\\tSM:$"{sample_name}"' -Y -M -C ref.fa $"{i}" $"{i/R1/R2}" | samtools-1
.3 view --threads 4 -b - | samtools-1.3 sort --threads 4 -o $"{i/R1/bwamem}".tmp.sort.bam - \"  > step2.2_bwamem_tmp_$"{n}"; done; chmod a+x step2.2_bwamem_tmp_*
touch step2_FINISHED" > step2.1_bwasplitter

chmod a+x step2.1_bwasplitter



# merge mapping, mark duplicates, generate stats, and finalise

echo -e "# merge mapping, mark duplicates, generate stats, and finalise
sample_name=$"{1}"
ls -1 *.tmp.sort.bam > bam.fofn
samtools-1.3 merge --threads 4 -cpf -b bam.fofn tmp.merged.sorted.bam
#rm *.tmp.sort.bam
java -Xmx20g -jar /nfs/users/nfs_s/sd21/lustre118_link/software/picard-tools-2.5.0/picard.jar MarkDuplicates INPUT=tmp.merged.sorted.bam OUTPUT=tmp.merged.sorted.marked.bam
METRICS_FILE=tmp.merged.sorted.marked.metrics TMP_DIR=$PWD/tmp
samtools-1.3 flagstat tmp.merged.sorted.marked.bam > $"{sample_name}".merged.sorted.marked.flagstat
#samtools-1.3 stats tmp.merged.sorted.marked.bam | grep ^SN | cut -f 2- > $"{sample_name}".merged.sorted.marked.stats
bamtools stats -in tmp.merged.sorted.marked.bam > $"{sample_name}".merged.sorted.marked.bamstats
samtools-1.3 view --threads 4 -F 12 -b tmp.merged.sorted.marked.bam -o $"{sample_name}".merged.sorted.marked.bam
samtools-1.3 view --threads 4 -f 12 tmp.merged.sorted.marked.bam -o $"{sample_name}".unmapped.bam
samtools-1.3 index -b $"{sample_name}".merged.sorted.marked.bam
rm R[12]_*
rm *.tmp.*
mv *.[eo] logfiles/
touch step3_FINISHED
touch bam_splitter_COMPLETE" > step3_bwasplitter
chmod a+x step3_bwasplitter



#----- RELEASE THE KRAKEN!

# run - reference and paired read setup
bsub -q normal -R'span[hosts=1] select[mem>10000] rusage[mem=10000]' -n1 -M10000 -J step1_bwasplitter_${ID} -e step1_bwasplitter.e -o step1_bwasplitter.o ./step1_bwasplitter
 ${sample_name} ${reference} ${read1} ${read2}


# run - prepare mapping scripts
bsub -q normal -w "done(step1_bwasplitter_${ID})" -R'span[hosts=1] select[mem>2500] rusage[mem=2500]' -n1 -M2500 -J step2.1_bwasplitter_${ID} -e step2.1_bwasplitter.e -o ste
p2.1_bwasplitter.o ./step2.1_bwasplitter ${sample_name}

while [ ! -f step1_FINISHED ]
do
  sleep 2
done

jobs=$( ls -1 R1_tmp_* | wc -l )


# run - mapping in array
bsub -q normal -w "done(step2.1_bwasplitter_${ID})"  -R'span[hosts=1] select[mem>10000] rusage[mem=10000]' -n6 -M10000 -J step2.2_bwasplitter_${ID}_[1-$jobs] -e step2.2_bwas
plitter[1-$jobs].e -o step2.2_bwasplitter[1-$jobs].o ./step2.2_bwamem_tmp_\$LSB_JOBINDEX


# run - merge mapping data into a single bam, mark duplicates, and clean up
bsub -q normal -w "done(step2.2_bwasplitter_${ID}_[1-$jobs])"  -R'span[hosts=1] select[mem>20000] rusage[mem=20000]' -n6 -M20000 -J step3_bwasplitter_${ID} -e logfiles/step3
_bwasplitter.e -o logfiles/step3_bwasplitter.o ./step3_bwasplitter ${sample_name}

#####################################################################
# Once completed, perform quality check of read alignment using MultiQC

multiqc *<common_end_of_directory>/*flagstats


#####################################################################

# Next, make a VCF file using samtools and bcftools:

samtools-1.3 mpileup -B -q 20 -Q 30 \
--ff DUP \
-uDf tc_171026.renamed.fa \
-b poolseq_bam_files/bam.list | \
bcftools-1.5 call -mv -O v > <file_name>.poolseq.variants.vcf 

#####################################################################

# Check the data:

# 1. Calculate mean depth of sites using VCFtools, remove those spuriously high/low as required:

# 2. Calculate the percentage missingness per site, remove those which would be unhelpful:

# 3. Calculate the percentage missingness per individual, decide whether to remove any individuals:

#####################################################################

# Plot a PCA of individuals:

install.package(gdsfmt)
install.package(SNPRelate)
install.package(ggrepel)

library(gdsfmt)
library(SNPRelate)
library(ggplot2)
library(ggrepel)

#---- INPUT FILES
vcf="<file_name>.vcf"
#group="host"

#---- Run script
#colour_group=read.table(group, header=F)

SNPRelate::snpgdsVCF2GDS(vcf.fn=vcf, out.fn="out.recode.vcf.gds")
genofile_vcf <- snpgdsOpen(filename="out.recode.vcf.gds", readonly = FALSE, allow.duplicate = TRUE)
vcf_pca <- snpgdsPCA(genofile_vcf, autosome.only=FALSE)

# make plot
pdf("Fl.v2b7c.vcf.PCA.pdf")
ggplot() + geom_point(aes(vcf_pca$eigenvect[,1],vcf_pca$eigenvect[,2]), colour=pop_map$V3) + ylab(paste0("PC2: ",vcf_pca$varprop[2])) + xlab(paste0("PC1: ",vcf_pca$varprop[1])) + geom_text_repel(aes(vcf_pca$eigenvect[,1],vcf_pca$eigenvect[,2], label=vcf_pca$sample.id), cex=1)
dev.off()

png("Fl.v2b7c.vcf.PCA.png")
ggplot() + geom_point(aes(vcf_pca$eigenvect[,1],vcf_pca$eigenvect[,2]), colour=pop_map$V3) + geom_text_repel(aes(vcf_pca$eigenvect[,1],vcf_pca$eigenvect[,2], label=vcf_pca$sample.id), cex=1) + ylab(paste0("PC2: ",vcf_pca$varprop[2])) + xlab(paste0("PC1: ",vcf_pca$varprop[1]))
dev.off()

####### NOTE - alternative way to plot PCA #########################

# You will first need to make a plink file. 
# Use plink 1.9 to do this. (https://www.cog-genomics.org/plink/1.9/)
# Can use the vcf file as input.



#####################################################################

# Determine Kinship analysis - are any individuals going to bias your data as they are closely related?
# Or, are these what you are looking for? 

#####################################################################

# Next, calculate the Fst values between your populations (as you like) using VCFtools:







